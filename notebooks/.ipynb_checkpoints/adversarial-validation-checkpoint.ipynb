{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several people have reported a discrepancy between CV and LB scores. The main idea behind this kernel is to have a quick and dirty check: how different are the distributions of the classes between training and test sets? The approach I use is adversarial validation:\n",
    "\n",
    "http://fastml.com/adversarial-validation-part-one/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from functools import partial\n",
    "from sklearn import metrics\n",
    "from collections import Counter\n",
    "import json\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "import time\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from PIL import Image, ImageFile\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.optim import lr_scheduler\n",
    "import os\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings\n",
    "bs = 64 \n",
    "sz = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Making pretrained weights work without needing to find the default filename\n",
    "if not os.path.exists('/tmp/.cache/torch/checkpoints/'):\n",
    "        os.makedirs('/tmp/.cache/torch/checkpoints/')\n",
    "!cp '../input/resnet50/resnet50.pth' '/tmp/.cache/torch/checkpoints/resnet50-19c8e357.pth'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The point of this block is to combine the training and test data into a single data frame, which can subsequently be used in our pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training images\n",
    "base_image_dir = os.path.join('..', 'input/aptos2019-blindness-detection/')\n",
    "train_dir = os.path.join(base_image_dir,'train_images/')\n",
    "df = pd.read_csv(os.path.join(base_image_dir, 'train.csv'))\n",
    "df['path'] = df['id_code'].map(lambda x: os.path.join(train_dir,'{}.png'.format(x)))\n",
    "df = df.drop(columns=['id_code'])\n",
    "df = df.sample(frac=1).reset_index(drop=True) #shuffle dataframe\n",
    "df['is_test'] = 0\n",
    "df.drop('diagnosis', axis = 1, inplace = True)\n",
    "\n",
    "df1 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test images\n",
    "base_image_dir = os.path.join('..', 'input/aptos2019-blindness-detection/')\n",
    "train_dir = os.path.join(base_image_dir,'test_images/')\n",
    "df = pd.read_csv(os.path.join(base_image_dir, 'test.csv'))\n",
    "df['path'] = df['id_code'].map(lambda x: os.path.join(train_dir,'{}.png'.format(x)))\n",
    "df = df.drop(columns=['id_code'])\n",
    "df = df.sample(frac=1).reset_index(drop=True) #shuffle dataframe\n",
    "df['is_test'] = 1\n",
    "df2 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total = pd.concat([df1,df2], axis =0 )\n",
    "df_total = df_total.sample(frac=1).reset_index(drop=True) \n",
    "del df1, df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# add cv folds indices (yes, i know it's ugly :-)\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "df_total['fold_id'] = -1\n",
    "\n",
    "for (nf, (train_index, test_index)) in enumerate(kf.split(df_total)):\n",
    "    df_total['fold_id'][test_index] = nf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop over folds - check performance for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = np.zeros((5,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 4: 0.9101\n"
     ]
    }
   ],
   "source": [
    "for ii in range(0, 5):\n",
    "    \n",
    "    # create this split for training / validation \n",
    "    df = df_total.copy()\n",
    "    df['is_valid'] = (df['fold_id'] == ii) + 0\n",
    "    df.drop('fold_id', axis = 1, inplace = True)\n",
    "    \n",
    "    # create the data object\n",
    "    tfms = get_transforms(do_flip=True,flip_vert=True,max_rotate=360,max_warp=0,max_zoom=1.1,max_lighting=0.1,p_lighting=0.5)\n",
    "    src = (ImageList.from_df(df=df,path='./',cols='path') \n",
    "        .split_from_df() \n",
    "        .label_from_df(cols='is_test') \n",
    "      )\n",
    "    data= (src.transform(tfms,size=sz,resize_method=ResizeMethod.SQUISH,padding_mode='zeros')\n",
    "        .databunch(bs=bs,num_workers=4)\n",
    "        .normalize(imagenet_stats)   \n",
    "       )\n",
    "    \n",
    "    # train a model for this fold - no optimization\n",
    "    learn = cnn_learner(data, base_arch = models.resnet50)\n",
    "    learn.unfreeze()\n",
    "    learn.fit_one_cycle(1, max_lr = slice(1e-6,1e-3))\n",
    "    \n",
    "    # evaluate performance\n",
    "    img = learn.data.valid_dl\n",
    "    xpred = learn.get_preds(img)\n",
    "    xscore = roc_auc_score(xpred[1],xpred[0][:,1])\n",
    "    print('fold '+str(ii) + ': ' + str(np.round(xscore, 4)))\n",
    "\n",
    "    res[ii] = xscore\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen from the results above (each fold has AUC > 0.9), even with a clearly underfitting model (validation loss < training loss) we can quite accurately distinguish the training and test sets. This means garden variety random split just won't do the job :-("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.901727]\n",
      " [0.914371]\n",
      " [0.920532]\n",
      " [0.910776]\n",
      " [0.910139]]\n"
     ]
    }
   ],
   "source": [
    "print(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
